Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,92.4303472340107,0:00:01,8.57324430346489,0:00:00,"{'f1': 0.08594449418084153, 'precision': 0.6857142857142857, 'accuracy': 0.7677434030937216, 'roc_auc_score': 0.519638073547165}",19.29948326945305,"{'f1': 0.07864302235929067, 'precision': 0.6296296296296297, 'accuracy': 0.7669883981671054, 'roc_auc_score': 0.5171365289221457}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
2,66.42083865404129,0:00:01,7.673212319612503,0:00:00,"{'f1': 0.2815158546017015, 'precision': 0.7398373983739838, 'accuracy': 0.7886715195632393, 'roc_auc_score': 0.577359904152489}",17.210135489702225,"{'f1': 0.33184143222506396, 'precision': 0.7456896551724138, 'accuracy': 0.7962367163888077, 'roc_auc_score': 0.5953923984782243}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
3,60.221191704273224,0:00:01,7.42085000872612,0:00:00,"{'f1': 0.3726884779516358, 'precision': 0.7298050139275766, 'accuracy': 0.7993630573248408, 'roc_auc_score': 0.6106374538237619}",16.45728451013565,"{'f1': 0.4099970246950313, 'precision': 0.7416576964477933, 'accuracy': 0.8066686165545481, 'roc_auc_score': 0.6263174972675298}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
4,57.95477253198624,0:00:01,7.261094003915787,0:00:00,"{'f1': 0.4172366621067032, 'precision': 0.7349397590361446, 'accuracy': 0.8061874431301183, 'roc_auc_score': 0.6292314374588431}",16.206160843372345,"{'f1': 0.45620022753128553, 'precision': 0.7398523985239852, 'accuracy': 0.8135907185336844, 'roc_auc_score': 0.6468656990919791}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
5,56.805098593235016,0:00:01,7.025107204914093,0:00:00,"{'f1': 0.44651162790697674, 'precision': 0.7336244541484717, 'accuracy': 0.8105095541401274, 'roc_auc_score': 0.6422440603661359}",15.915645599365234,"{'f1': 0.4836202109938923, 'precision': 0.7444444444444445, 'accuracy': 0.8186604270254461, 'roc_auc_score': 0.6599652923743063}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
6,55.734984785318375,0:00:01,6.980226993560791,0:00:00,"{'f1': 0.47173489278752434, 'precision': 0.7378048780487805, 'accuracy': 0.815059144676979, 'roc_auc_score': 0.6540929550881631}",15.622239828109741,"{'f1': 0.4983624454148472, 'precision': 0.7410714285714286, 'accuracy': 0.8208053036950376, 'roc_auc_score': 0.6673222055237935}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
7,54.68411260843277,0:00:01,7.0320132076740265,0:00:00,"{'f1': 0.4904214559386973, 'precision': 0.7398843930635838, 'accuracy': 0.8184713375796179, 'roc_auc_score': 0.6632258185952955}",15.49232330918312,"{'f1': 0.5117535801134828, 'precision': 0.7462568951930654, 'accuracy': 0.8238276299112801, 'roc_auc_score': 0.674120643812006}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
8,54.64933252334595,0:00:01,6.92485785484314,0:00:00,"{'f1': 0.49713193116634796, 'precision': 0.7471264367816092, 'accuracy': 0.8205186533212011, 'roc_auc_score': 0.6665390430021877}",15.397080391645432,"{'f1': 0.5170836696260426, 'precision': 0.7478599221789883, 'accuracy': 0.8249975626401482, 'roc_auc_score': 0.6768711377585337}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
9,54.28737097978592,0:00:01,6.815996527671814,0:00:00,"{'f1': 0.5009487666034155, 'precision': 0.7415730337078652, 'accuracy': 0.8205186533212011, 'roc_auc_score': 0.6685085827270854}",15.233145326375961,"{'f1': 0.5236188951160928, 'precision': 0.7460076045627376, 'accuracy': 0.8259725065808716, 'roc_auc_score': 0.680344002228014}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
10,53.85738033056259,0:00:01,6.840533256530762,0:00:00,"{'f1': 0.5053695514845231, 'precision': 0.746268656716418, 'accuracy': 0.8218835304822566, 'roc_auc_score': 0.6707173989983468}",15.4019635617733,"{'f1': 0.5268759978712082, 'precision': 0.746606334841629, 'accuracy': 0.8266549673393779, 'roc_auc_score': 0.682066535648226}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
11,53.69446137547493,0:00:01,6.789050430059433,0:00:00,"{'f1': 0.508816120906801, 'precision': 0.7467652495378928, 'accuracy': 0.8225659690627843, 'roc_auc_score': 0.67247832037561}",15.286679893732071,"{'f1': 0.5285524568393094, 'precision': 0.746436609152288, 'accuracy': 0.826947450521595, 'roc_auc_score': 0.6829667006473853}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss
12,53.80426335334778,0:00:01,6.874548316001892,0:00:00,"{'f1': 0.508816120906801, 'precision': 0.7467652495378928, 'accuracy': 0.8225659690627843, 'roc_auc_score': 0.67247832037561}",15.385824084281921,"{'f1': 0.5280212483399734, 'precision': 0.7456864216054013, 'accuracy': 0.8267524617334503, 'roc_auc_score': 0.6826972107785438}",0:00:00,20220125_1808,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.0002_Batch256_LossBCEWithLogitsLoss

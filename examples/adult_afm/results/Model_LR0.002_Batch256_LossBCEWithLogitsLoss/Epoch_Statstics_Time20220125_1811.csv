Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,59.932782500982285,0:00:01,6.747719347476959,0:00:00,"{'f1': 0.4808813998703824, 'precision': 0.7479838709677419, 'accuracy': 0.8177888989990901, 'roc_auc_score': 0.6585105876306859}",14.920792996883392,"{'f1': 0.5098782138024357, 'precision': 0.7458432304038005, 'accuracy': 0.8234376523349908, 'roc_auc_score': 0.6731565810492686}",0:00:00,20220125_1810,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
2,50.98487788438797,0:00:01,6.470651179552078,0:00:00,"{'f1': 0.5095057034220533, 'precision': 0.7570621468926554, 'accuracy': 0.8239308462238398, 'roc_auc_score': 0.672717596921974}",14.53802353143692,"{'f1': 0.5212965443343155, 'precision': 0.7478862413528056, 'accuracy': 0.8257775177927269, 'roc_auc_score': 0.6790826519673786}",0:00:00,20220125_1810,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
3,49.99857848882675,0:00:01,6.333579033613205,0:00:00,"{'f1': 0.5159674389480275, 'precision': 0.7490909090909091, 'accuracy': 0.8241583257506825, 'roc_auc_score': 0.6761494614281359}",14.61326801776886,"{'f1': 0.532129580456718, 'precision': 0.7511244377811095, 'accuracy': 0.8282148776445354, 'roc_auc_score': 0.684789231965697}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
4,49.46518360078335,0:00:01,6.3377383053302765,0:00:00,"{'f1': 0.5516417910447761, 'precision': 0.7356687898089171, 'accuracy': 0.8291628753412192, 'roc_auc_score': 0.6958468550249358}",14.449639827013016,"{'f1': 0.5635808748728383, 'precision': 0.7386666666666667, 'accuracy': 0.8326996197718631, 'roc_auc_score': 0.7027481293088953}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
5,49.16609600186348,0:00:01,6.362085610628128,0:00:00,"{'f1': 0.548714883442917, 'precision': 0.7332268370607029, 'accuracy': 0.828252957233849, 'roc_auc_score': 0.6942648919704895}",14.483529210090637,"{'f1': 0.5644140723867376, 'precision': 0.7340355497037525, 'accuracy': 0.8322121478015014, 'roc_auc_score': 0.703420500882798}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
6,49.13501328229904,0:00:01,6.282570481300354,0:00:00,"{'f1': 0.5087939698492462, 'precision': 0.7431192660550459, 'accuracy': 0.8221110100090991, 'roc_auc_score': 0.6725079804004275}",14.272013008594513,"{'f1': 0.5296610169491526, 'precision': 0.7440476190476191, 'accuracy': 0.8268499561275227, 'roc_auc_score': 0.6836112745922313}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
7,48.96916052699089,0:00:01,6.341313600540161,0:00:00,"{'f1': 0.49554140127388535, 'precision': 0.7437858508604207, 'accuracy': 0.8198362147406734, 'roc_auc_score': 0.6657628914873732}",14.394884437322617,"{'f1': 0.527859237536657, 'precision': 0.7505686125852918, 'accuracy': 0.8273374280978844, 'roc_auc_score': 0.682513819993274}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
8,48.799923092126846,0:00:01,6.383538097143173,0:00:00,"{'f1': 0.5091137649277184, 'precision': 0.7444852941176471, 'accuracy': 0.8223384895359418, 'roc_auc_score': 0.6726572786984268}",14.663776516914368,"{'f1': 0.5302226935312832, 'precision': 0.746268656716418, 'accuracy': 0.827239933703812, 'roc_auc_score': 0.6838668656465444}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
9,48.819182962179184,0:00:01,6.3405782878398895,0:00:00,"{'f1': 0.49649904519414384, 'precision': 0.7442748091603053, 'accuracy': 0.8200636942675159, 'roc_auc_score': 0.6662404464061888}",14.359103500843048,"{'f1': 0.5261752136752137, 'precision': 0.7507621951219512, 'accuracy': 0.8270449449156674, 'roc_auc_score': 0.6816136549941146}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
10,48.75061586499214,0:00:01,6.362282633781433,0:00:00,"{'f1': 0.501269035532995, 'precision': 0.7466918714555766, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6686282210002672}",14.414656907320023,"{'f1': 0.5291455948895395, 'precision': 0.750188679245283, 'accuracy': 0.8275324168860291, 'roc_auc_score': 0.6832083928871701}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
11,48.4978993833065,0:00:01,6.422863125801086,0:00:00,"{'f1': 0.5044136191677175, 'precision': 0.7421150278293135, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6702695041043485}",14.310708612203598,"{'f1': 0.5326633165829147, 'precision': 0.7464788732394366, 'accuracy': 0.8277274056741737, 'roc_auc_score': 0.6851782148562301}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss
12,48.607387006282806,0:00:01,6.383096843957901,0:00:00,"{'f1': 0.5034700315457413, 'precision': 0.741635687732342, 'accuracy': 0.8209736123748863, 'roc_auc_score': 0.6697919491855329}",14.154595002532005,"{'f1': 0.5326633165829147, 'precision': 0.7464788732394366, 'accuracy': 0.8277274056741737, 'roc_auc_score': 0.6851782148562301}",0:00:00,20220125_1811,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR0.002_Batch256_LossBCEWithLogitsLoss

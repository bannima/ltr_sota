Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,130.25690549612045,0:00:01,13.981826722621918,0:00:00,"{'f1': 0.24346257889990983, 'precision': 0.23057216054654142, 'accuracy': 0.6182893539581438, 'roc_auc_score': 0.49442206158276725}",31.866436064243317,"{'f1': 0.246670526925304, 'precision': 0.23244816296835213, 'accuracy': 0.6194793799356537, 'roc_auc_score': 0.4965490741129981}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
2,118.24838489294052,0:00:01,12.906671702861786,0:00:00,"{'f1': 0.23505775991963837, 'precision': 0.2478813559322034, 'accuracy': 0.6535486806187443, 'roc_auc_score': 0.5057460594232893}",29.457553684711456,"{'f1': 0.22739901688394953, 'precision': 0.2367601246105919, 'accuracy': 0.6475577654284879, 'roc_auc_score': 0.4997903354632588}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
3,109.0147677063942,0:00:01,12.148051142692566,0:00:00,"{'f1': 0.21481062747314866, 'precision': 0.2631578947368421, 'accuracy': 0.6840309372156506, 'roc_auc_score': 0.5113087400392938}",27.673709094524384,"{'f1': 0.2002888781896967, 'precision': 0.2415795586527294, 'accuracy': 0.6761236228916837, 'roc_auc_score': 0.5020758365562469}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
4,102.09086668491364,0:00:01,11.588353872299194,0:00:00,"{'f1': 0.19334588826114252, 'precision': 0.28205128205128205, 'accuracy': 0.7076888080072793, 'roc_auc_score': 0.5150185246818464}",26.166976749897003,"{'f1': 0.17384196185286105, 'precision': 0.25767366720516965, 'accuracy': 0.7043969971726626, 'roc_auc_score': 0.5068618368505129}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
5,95.82195889949799,0:00:01,11.056721448898315,0:00:00,"{'f1': 0.15006821282401092, 'precision': 0.26252983293556087, 'accuracy': 0.7165605095541401, 'roc_auc_score': 0.5063978669879076}",25.27315330505371,"{'f1': 0.1408199643493761, 'precision': 0.25374732334047106, 'accuracy': 0.7180462123427903, 'roc_auc_score': 0.5041885877333109}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
6,93.03845185041428,0:00:01,10.774075388908386,0:00:00,"{'f1': 0.13728323699421965, 'precision': 0.2818991097922849, 'accuracy': 0.7283894449499545, 'roc_auc_score': 0.5092375291716326}",24.514787435531616,"{'f1': 0.13172894236858773, 'precision': 0.2865013774104683, 'accuracy': 0.7326703714536414, 'roc_auc_score': 0.5096641163611906}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
7,89.78414380550385,0:00:01,10.544923782348633,0:00:00,"{'f1': 0.11102299762093577, 'precision': 0.32710280373831774, 'accuracy': 0.7449954504094631, 'roc_auc_score': 0.5119298894051825}",23.985476791858673,"{'f1': 0.108145106091718, 'precision': 0.3224489795918367, 'accuracy': 0.7459296090474797, 'roc_auc_score': 0.5112694951235918}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
8,87.3379437327385,0:00:01,10.385543286800385,0:00:00,"{'f1': 0.09275834011391375, 'precision': 0.3131868131868132, 'accuracy': 0.7463603275705186, 'roc_auc_score': 0.5085583431225675}",23.490249693393707,"{'f1': 0.1002805049088359, 'precision': 0.3404761904761905, 'accuracy': 0.7498293848103734, 'roc_auc_score': 0.5116999905414494}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
9,85.48124879598618,0:00:01,10.191785752773285,0:00:00,"{'f1': 0.08244023083264634, 'precision': 0.30120481927710846, 'accuracy': 0.7468152866242038, 'roc_auc_score': 0.5065591433728525}",23.174372673034668,"{'f1': 0.0933852140077821, 'precision': 0.3341772151898734, 'accuracy': 0.7501218679925904, 'roc_auc_score': 0.5103330460736506}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
10,84.8235427737236,0:00:01,10.297282487154007,0:00:00,"{'f1': 0.07628524046434493, 'precision': 0.2893081761006289, 'accuracy': 0.7465878070973613, 'roc_auc_score': 0.5050968185915881}",22.951040029525757,"{'f1': 0.08562254727078131, 'precision': 0.32345013477088946, 'accuracy': 0.7501218679925904, 'roc_auc_score': 0.508632713973432}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
11,83.94073301553726,0:00:01,10.117224037647247,0:00:00,"{'f1': 0.07660283097418817, 'precision': 0.2987012987012987, 'accuracy': 0.7477252047315741, 'roc_auc_score': 0.5058433100815851}",22.892189264297485,"{'f1': 0.08524355300859598, 'precision': 0.33055555555555555, 'accuracy': 0.7509993175392415, 'roc_auc_score': 0.5090660995039517}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
12,83.7273541688919,0:00:01,10.190253585577011,0:00:00,"{'f1': 0.07660283097418817, 'precision': 0.2987012987012987, 'accuracy': 0.7477252047315741, 'roc_auc_score': 0.5058433100815851}",22.849941313266754,"{'f1': 0.08536585365853659, 'precision': 0.3342696629213483, 'accuracy': 0.7513892951155309, 'roc_auc_score': 0.5093216905582647}",0:00:00,20220125_1807,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_afm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss

Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,155.2628629207611,0:00:02,16.30298349261284,0:00:00,"{'f1': 0.0, 'precision': 0.0, 'accuracy': 0.7618289353958144, 'roc_auc_score': 0.5}",37.5988233089447,"{'f1': 0.0, 'precision': 0.0, 'accuracy': 0.7628936336160671, 'roc_auc_score': 0.5}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
2,118.15970161557198,0:00:01,14.010644555091858,0:00:00,"{'f1': 0.020735155513666347, 'precision': 0.7857142857142857, 'accuracy': 0.763648771610555, 'roc_auc_score': 0.5048052092129741}",32.26409691572189,"{'f1': 0.02030869212022746, 'precision': 0.8333333333333334, 'accuracy': 0.7648435214975139, 'roc_auc_score': 0.5048203138136876}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
3,110.41645959019661,0:00:01,13.350409895181656,0:00:00,"{'f1': 0.1367221735319895, 'precision': 0.8297872340425532, 'accuracy': 0.7759326660600546, 'roc_auc_score': 0.5348605108996314}",30.60668671131134,"{'f1': 0.14634146341463414, 'precision': 0.8369098712446352, 'accuracy': 0.7782002534854245, 'roc_auc_score': 0.5376623455103413}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
4,108.77960848808289,0:00:01,12.962681084871292,0:00:00,"{'f1': 0.32547528517110264, 'precision': 0.7985074626865671, 'accuracy': 0.7982256596906279, 'roc_auc_score': 0.5941346445345843}",30.013312846422195,"{'f1': 0.3397807865892972, 'precision': 0.7865671641791044, 'accuracy': 0.800331480939846, 'roc_auc_score': 0.5992096592819909}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
5,107.76425585150719,0:00:01,13.036086797714233,0:00:00,"{'f1': 0.2624798711755234, 'precision': 0.8358974358974359, 'accuracy': 0.7916287534121929, 'roc_auc_score': 0.5730639062309724}",30.08305075764656,"{'f1': 0.2782134333446982, 'precision': 0.8143712574850299, 'accuracy': 0.7936043677488545, 'roc_auc_score': 0.5779390869345887}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
6,106.91676339507103,0:00:01,12.958356887102127,0:00:00,"{'f1': 0.36524300441826213, 'precision': 0.797427652733119, 'accuracy': 0.8039126478616925, 'roc_auc_score': 0.6090278270923223}",29.95822224020958,"{'f1': 0.392483056069008, 'precision': 0.7825552825552825, 'accuracy': 0.8077410548893439, 'roc_auc_score': 0.619652266899277}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
7,106.00857627391815,0:00:01,12.977475851774216,0:00:00,"{'f1': 0.33933933933933935, 'precision': 0.7929824561403509, 'accuracy': 0.7998180163785259, 'roc_auc_score': 0.5991188120703752}",29.74269723892212,"{'f1': 0.36656151419558364, 'precision': 0.7872628726287263, 'accuracy': 0.8042312567027395, 'roc_auc_score': 0.6094170642761055}",0:00:00,20220117_1711,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
8,105.34397187829018,0:00:01,12.813340291380882,0:00:00,"{'f1': 0.3320754716981132, 'precision': 0.7913669064748201, 'accuracy': 0.7986806187443131, 'roc_auc_score': 0.5964027808554806}",29.435919642448425,"{'f1': 0.36219473517285133, 'precision': 0.7919556171983356, 'accuracy': 0.8039387735205226, 'roc_auc_score': 0.6078084275685219}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
9,104.89877060055733,0:00:01,12.685352981090546,0:00:00,"{'f1': 0.3430711610486891, 'precision': 0.7951388888888888, 'accuracy': 0.8005004549590536, 'roc_auc_score': 0.6005514768268222}",29.71625816822052,"{'f1': 0.3659385881608104, 'precision': 0.7950481430536451, 'accuracy': 0.8047187286731013, 'roc_auc_score': 0.6093114700689424}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
10,104.53117641806602,0:00:01,12.687799274921417,0:00:00,"{'f1': 0.42945629731589813, 'precision': 0.7684729064039408, 'accuracy': 0.8114194722474978, 'roc_auc_score': 0.6349630946585433}",29.45218139886856,"{'f1': 0.45764192139737997, 'precision': 0.7836490528414756, 'accuracy': 0.818367943843229, 'roc_auc_score': 0.6477295800403565}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
11,103.61771777272224,0:00:01,12.698368668556213,0:00:00,"{'f1': 0.4552736982643524, 'precision': 0.7560975609756098, 'accuracy': 0.8143767060964513, 'roc_auc_score': 0.646423414536207}",29.393055886030197,"{'f1': 0.48131370328425827, 'precision': 0.7727272727272727, 'accuracy': 0.8213902700594716, 'roc_auc_score': 0.6587788485791156}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
12,103.59939417243004,0:00:01,12.72342848777771,0:00:00,"{'f1': 0.38908829863603733, 'precision': 0.7832369942196532, 'accuracy': 0.8064149226569609, 'roc_auc_score': 0.6182200106490897}",29.230709314346313,"{'f1': 0.4201273113064566, 'precision': 0.7993079584775087, 'accuracy': 0.813493224139612, 'roc_auc_score': 0.6313571180847486}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
13,103.14404276013374,0:00:01,12.657626658678055,0:00:00,"{'f1': 0.3282904689863843, 'precision': 0.7890909090909091, 'accuracy': 0.7979981801637852, 'roc_auc_score': 0.5949701160990336}",29.481086432933807,"{'f1': 0.3713561470215462, 'precision': 0.8093922651933702, 'accuracy': 0.8065711221604758, 'roc_auc_score': 0.6116590823104086}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
14,102.73055022954941,0:00:01,12.554147839546204,0:00:00,"{'f1': 0.4398907103825136, 'precision': 0.7721822541966427, 'accuracy': 0.813466787989081, 'roc_auc_score': 0.6395893455487004}",28.844087570905685,"{'f1': 0.46491481374530763, 'precision': 0.7807953443258971, 'accuracy': 0.8193428877839525, 'roc_auc_score': 0.651060750168152}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
15,102.2910916954279,0:00:01,12.449233293533325,0:00:00,"{'f1': 0.40113394755492565, 'precision': 0.7774725274725275, 'accuracy': 0.8077797998180164, 'roc_auc_score': 0.6230548798868812}",28.829593271017075,"{'f1': 0.44128113879003555, 'precision': 0.7914893617021277, 'accuracy': 0.8163205615677098, 'roc_auc_score': 0.6404365646544476}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
16,101.94823217391968,0:00:01,12.491105049848557,0:00:00,"{'f1': 0.4498644986449864, 'precision': 0.7738927738927739, 'accuracy': 0.8152866242038217, 'roc_auc_score': 0.6440662981408584}",28.864626854658127,"{'f1': 0.48061573546180164, 'precision': 0.783457249070632, 'accuracy': 0.822365214000195, 'roc_auc_score': 0.6584259658231041}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
17,101.85705628991127,0:00:01,12.451264828443527,0:00:00,"{'f1': 0.3605341246290801, 'precision': 0.8073089700996677, 'accuracy': 0.8039126478616925, 'roc_auc_score': 0.607386543988241}",28.68920025229454,"{'f1': 0.3778337531486146, 'precision': 0.8064516129032258, 'accuracy': 0.8073510773130546, 'roc_auc_score': 0.6141539852026231}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
18,101.25966513156891,0:00:01,12.364672094583511,0:00:00,"{'f1': 0.4192200557103064, 'precision': 0.7737789203084833, 'accuracy': 0.8102820746132848, 'roc_auc_score': 0.6306057803395674}",28.564145237207413,"{'f1': 0.45812664137729797, 'precision': 0.7889447236180904, 'accuracy': 0.818952910207663, 'roc_auc_score': 0.6479712722801413}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
19,100.52508480846882,0:00:01,12.457504540681839,0:00:00,"{'f1': 0.49420849420849416, 'precision': 0.757396449704142, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6650173981712884}",28.7782464325428,"{'f1': 0.5237191650853891, 'precision': 0.7684964200477327, 'accuracy': 0.8287023496148972, 'roc_auc_score': 0.6800077244829326}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
20,100.39598560333252,0:00:01,12.345963716506958,0:00:00,"{'f1': 0.45466847090663054, 'precision': 0.7795823665893271, 'accuracy': 0.8166515013648772, 'roc_auc_score': 0.6462751144121198}",28.62503084540367,"{'f1': 0.49577940348902644, 'precision': 0.785204991087344, 'accuracy': 0.8252900458223652, 'roc_auc_score': 0.6657272837144779}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
21,100.59935811161995,0:00:01,12.414747834205627,0:00:00,"{'f1': 0.44368600682593856, 'precision': 0.777511961722488, 'accuracy': 0.814604185623294, 'roc_auc_score': 0.6413206069011463}",28.251435324549675,"{'f1': 0.48835888699602503, 'precision': 0.7889908256880734, 'accuracy': 0.8243151018816418, 'roc_auc_score': 0.6621127249033126}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
22,100.2049569785595,0:00:01,12.24238321185112,0:00:00,"{'f1': 0.46617548559946415, 'precision': 0.7802690582959642, 'accuracy': 0.8186988171064604, 'roc_auc_score': 0.6515578785439095}",28.336920365691185,"{'f1': 0.49676875526833375, 'precision': 0.7843833185448092, 'accuracy': 0.8253875402164376, 'roc_auc_score': 0.6662162645031109}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
23,99.73245014250278,0:00:01,12.257637292146683,0:00:00,"{'f1': 0.44897959183673464, 'precision': 0.7801418439716312, 'accuracy': 0.8157415832575068, 'roc_auc_score': 0.6437083814952246}",28.474864542484283,"{'f1': 0.48096192384769537, 'precision': 0.7917059377945335, 'accuracy': 0.823242663546846, 'roc_auc_score': 0.658575962670254}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
24,99.9421329498291,0:00:01,12.305772542953491,0:00:00,"{'f1': 0.40656205420827396, 'precision': 0.8028169014084507, 'accuracy': 0.8107370336669699, 'roc_auc_score': 0.6256522710025061}",28.437181189656258,"{'f1': 0.45266272189349116, 'precision': 0.8069620253164557, 'accuracy': 0.8196353709661695, 'roc_auc_score': 0.6455846697914915}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
25,99.30009646713734,0:00:01,12.216738522052765,0:00:00,"{'f1': 0.4322446143154968, 'precision': 0.7933673469387755, 'accuracy': 0.8141492265696088, 'roc_auc_score': 0.6364264176137198}",28.379614740610123,"{'f1': 0.47089487402258906, 'precision': 0.7962781586679726, 'accuracy': 0.8218777420298333, 'roc_auc_score': 0.6538556467546661}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
26,99.55022652447224,0:00:01,12.250785410404205,0:00:00,"{'f1': 0.42718446601941745, 'precision': 0.779746835443038, 'accuracy': 0.8121019108280255, 'roc_auc_score': 0.6340979630692763}",28.15691713988781,"{'f1': 0.4721254355400697, 'precision': 0.8033596837944664, 'accuracy': 0.8227551915764844, 'roc_auc_score': 0.6544307266268707}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
27,99.01237797737122,0:00:01,12.290840744972229,0:00:00,"{'f1': 0.4523160762942779, 'precision': 0.7885985748218527, 'accuracy': 0.8171064604185623, 'roc_auc_score': 0.6452606845248536}",28.218752443790436,"{'f1': 0.4916169366297243, 'precision': 0.795768169273229, 'accuracy': 0.8255825290045823, 'roc_auc_score': 0.6636518675382547}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
28,99.34929740428925,0:00:01,12.278356403112411,0:00:00,"{'f1': 0.4534962661235574, 'precision': 0.784037558685446, 'accuracy': 0.8168789808917197, 'roc_auc_score': 0.6457678994684867}",28.058210983872414,"{'f1': 0.4923425978445831, 'precision': 0.793418647166362, 'accuracy': 0.8254850346105099, 'roc_auc_score': 0.6640130527997309}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
29,99.52054008841515,0:00:01,12.244388729333878,0:00:00,"{'f1': 0.4611223799864773, 'precision': 0.7893518518518519, 'accuracy': 0.8186988171064604, 'roc_auc_score': 0.6492600821981958}",28.05976250767708,"{'f1': 0.493771234428086, 'precision': 0.7927272727272727, 'accuracy': 0.8256800233986545, 'roc_auc_score': 0.664707625693627}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
30,98.84248483181,0:00:01,12.265052556991577,0:00:00,"{'f1': 0.4498977505112474, 'precision': 0.7857142857142857, 'accuracy': 0.8164240218380345, 'roc_auc_score': 0.6441562763892228}",28.229567766189575,"{'f1': 0.4883057615516258, 'precision': 0.7970204841713222, 'accuracy': 0.8250950570342205, 'roc_auc_score': 0.6620571296451992}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
31,99.43760815262794,0:00:01,12.238750100135803,0:00:00,"{'f1': 0.4687083888149134, 'precision': 0.7736263736263737, 'accuracy': 0.8184713375796179, 'roc_auc_score': 0.6527216067291751}",27.984786927700043,"{'f1': 0.5072222222222222, 'precision': 0.7816780821917808, 'accuracy': 0.8270449449156674, 'roc_auc_score': 0.671411662392803}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
32,98.99982759356499,0:00:01,12.17635703086853,0:00:00,"{'f1': 0.48357424441524305, 'precision': 0.7747368421052632, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6597652922382282}",28.185674518346786,"{'f1': 0.5220971726598957, 'precision': 0.7853014037985137, 'accuracy': 0.8302622599200546, 'roc_auc_score': 0.6789046735749118}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
33,99.09406778216362,0:00:01,12.186124205589294,0:00:00,"{'f1': 0.43580846634281745, 'precision': 0.7969543147208121, 'accuracy': 0.815059144676979, 'roc_auc_score': 0.6380083806681662}",28.117464870214462,"{'f1': 0.4733178654292343, 'precision': 0.8031496062992126, 'accuracy': 0.8229501803646291, 'roc_auc_score': 0.6549836051790818}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
34,99.0808777064085,0:00:01,12.315676659345627,0:00:00,"{'f1': 0.459349593495935, 'precision': 0.7902097902097902, 'accuracy': 0.8184713375796179, 'roc_auc_score': 0.6484542706585638}",28.328355610370636,"{'f1': 0.4914578587699316, 'precision': 0.799074074074074, 'accuracy': 0.8258750121867993, 'roc_auc_score': 0.6635601721456197}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
35,98.64421913027763,0:00:01,12.189447700977325,0:00:00,"{'f1': 0.4653665097511769, 'precision': 0.7863636363636364, 'accuracy': 0.8191537761601456, 'roc_auc_score': 0.6511999618982758}",27.97933354973793,"{'f1': 0.49816849816849823, 'precision': 0.7914055505819159, 'accuracy': 0.826362484157161, 'roc_auc_score': 0.6668552421388937}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
36,98.37148556113243,0:00:01,12.20527908205986,0:00:00,"{'f1': 0.49088541666666674, 'precision': 0.7709611451942741, 'accuracy': 0.8221110100090991, 'roc_auc_score': 0.6633167950175721}",28.01556184887886,"{'f1': 0.5333333333333333, 'precision': 0.7821939586645469, 'accuracy': 0.8321146534074291, 'roc_auc_score': 0.6847946443585001}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
37,98.0403166115284,0:00:01,12.20755785703659,0:00:00,"{'f1': 0.4514363885088919, 'precision': 0.7951807228915663, 'accuracy': 0.8175614194722475, 'roc_auc_score': 0.6449027678792199}",28.246001452207565,"{'f1': 0.48437947836056183, 'precision': 0.7994323557237465, 'accuracy': 0.8246075850638588, 'roc_auc_score': 0.6601790030687742}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
38,98.12799987196922,0:00:01,12.191523030400276,0:00:00,"{'f1': 0.47757255936675463, 'precision': 0.7718550106609808, 'accuracy': 0.8198362147406734, 'roc_auc_score': 0.6568999627253342}",27.987516582012177,"{'f1': 0.5069637883008357, 'precision': 0.7858376511226253, 'accuracy': 0.8274349224919567, 'roc_auc_score': 0.6712421704220615}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
39,98.37565463781357,0:00:01,12.143407732248306,0:00:00,"{'f1': 0.4719251336898396, 'precision': 0.7861915367483296, 'accuracy': 0.8202911737943585, 'roc_auc_score': 0.6542442497339868}",28.11242127418518,"{'f1': 0.5057471264367815, 'precision': 0.7947136563876652, 'accuracy': 0.8281173832504631, 'roc_auc_score': 0.6705559000336304}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
40,98.25111730396748,0:00:01,12.254885762929916,0:00:00,"{'f1': 0.5012919896640827, 'precision': 0.7744510978043913, 'accuracy': 0.824385805277525, 'roc_auc_score': 0.6684206008265451}",27.91614057123661,"{'f1': 0.53257328990228, 'precision': 0.7835463258785943, 'accuracy': 0.8321146534074291, 'roc_auc_score': 0.6843695613334455}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
41,98.8370506465435,0:00:01,12.152423739433289,0:00:00,"{'f1': 0.46133154001344995, 'precision': 0.7795454545454545, 'accuracy': 0.8177888989990901, 'roc_auc_score': 0.6493194022478306}",27.96831864118576,"{'f1': 0.4967504944899689, 'precision': 0.7940379403794038, 'accuracy': 0.826362484157161, 'roc_auc_score': 0.6661467704304692}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
42,98.16579020023346,0:00:01,12.16796624660492,0:00:00,"{'f1': 0.486592544146501, 'precision': 0.7717842323651453, 'accuracy': 0.8214285714285714, 'roc_auc_score': 0.6612276170194926}",27.967548459768295,"{'f1': 0.5251916757940854, 'precision': 0.7860655737704918, 'accuracy': 0.830944720678561, 'roc_auc_score': 0.6804855126534386}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
43,97.6306964457035,0:00:01,12.163343071937561,0:00:00,"{'f1': 0.5016202203499676, 'precision': 0.780241935483871, 'accuracy': 0.8250682438580528, 'roc_auc_score': 0.6685402390997269}",27.829085007309914,"{'f1': 0.5278080697928026, 'precision': 0.7831715210355987, 'accuracy': 0.8311397094667057, 'roc_auc_score': 0.6818885572557593}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
44,97.75077976286411,0:00:01,12.130681693553925,0:00:00,"{'f1': 0.4647414372061786, 'precision': 0.7828054298642534, 'accuracy': 0.8186988171064604, 'roc_auc_score': 0.6509013653022769}",28.097227320075035,"{'f1': 0.50126867775585, 'precision': 0.7973094170403587, 'accuracy': 0.8275324168860291, 'roc_auc_score': 0.6683304870102573}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
45,97.33095368742943,0:00:01,12.185542613267899,0:00:00,"{'f1': 0.46091644204851745, 'precision': 0.782608695652174, 'accuracy': 0.8180163785259327, 'roc_auc_score': 0.6491404439250137}",28.007869064807892,"{'f1': 0.5018325345362278, 'precision': 0.7982062780269058, 'accuracy': 0.8277274056741737, 'roc_auc_score': 0.6685999768790987}",0:00:00,20220117_1712,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
46,97.53989690542221,0:00:01,12.136869564652443,0:00:00,"{'f1': 0.49707981829980535, 'precision': 0.7753036437246964, 'accuracy': 0.8237033666969973, 'roc_auc_score': 0.6663314228284655}",28.031349301338196,"{'f1': 0.5319206737299647, 'precision': 0.7838270616493195, 'accuracy': 0.8320171590133567, 'roc_auc_score': 0.6840222748864975}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
47,97.6051504611969,0:00:01,12.128025472164154,0:00:00,"{'f1': 0.518939393939394, 'precision': 0.7653631284916201, 'accuracy': 0.8266606005459509, 'roc_auc_score': 0.677463486085313}",27.93833839893341,"{'f1': 0.5459401709401709, 'precision': 0.7789634146341463, 'accuracy': 0.8342595300770206, 'roc_auc_score': 0.6915847801412477}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
48,97.92354196310043,0:00:01,12.209398359060287,0:00:00,"{'f1': 0.489501312335958, 'precision': 0.7819706498951782, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6626009617263048}",27.99282842874527,"{'f1': 0.5220971726598957, 'precision': 0.7853014037985137, 'accuracy': 0.8302622599200546, 'roc_auc_score': 0.6789046735749118}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
49,97.93495881557465,0:00:01,12.122360348701477,0:00:00,"{'f1': 0.529925187032419, 'precision': 0.7630161579892281, 'accuracy': 0.8284804367606915, 'roc_auc_score': 0.6832534651607359}",27.955483108758926,"{'f1': 0.558005249343832, 'precision': 0.7714078374455733, 'accuracy': 0.835819440382178, 'roc_auc_score': 0.6984166123675803}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
50,97.51736477017403,0:00:01,12.171565473079681,0:00:00,"{'f1': 0.49740932642487046, 'precision': 0.772635814889336, 'accuracy': 0.8234758871701547, 'roc_auc_score': 0.6665103811512824}",27.97530034184456,"{'f1': 0.5276642136822023, 'precision': 0.7825383993532741, 'accuracy': 0.8310422150726333, 'roc_auc_score': 0.6818246594921809}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
51,97.4526050388813,0:00:01,12.072312742471695,0:00:00,"{'f1': 0.49967469095640854, 'precision': 0.7836734693877551, 'accuracy': 0.8250682438580528, 'roc_auc_score': 0.6675554692372782}",27.733971044421196,"{'f1': 0.5318801089918257, 'precision': 0.7883683360258481, 'accuracy': 0.8325046309837184, 'roc_auc_score': 0.6839166806793341}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
52,97.7884641289711,0:00:01,12.120690703392029,0:00:00,"{'f1': 0.49902534113060426, 'precision': 0.7804878048780488, 'accuracy': 0.8246132848043676, 'roc_auc_score': 0.6672568726412794}",27.902113139629364,"{'f1': 0.5286415711947626, 'precision': 0.7852512155591572, 'accuracy': 0.831529687042995, 'roc_auc_score': 0.6822858426517572}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
53,97.38088688254356,0:00:01,12.215821415185928,0:00:00,"{'f1': 0.5102564102564102, 'precision': 0.7758284600389863, 'accuracy': 0.8262056414922657, 'roc_auc_score': 0.6728975534187028}",27.983402967453003,"{'f1': 0.5391866415297603, 'precision': 0.7814207650273224, 'accuracy': 0.8331870917422248, 'roc_auc_score': 0.687906323566504}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
54,97.59262964129448,0:00:01,12.029570370912552,0:00:00,"{'f1': 0.4548540393754243, 'precision': 0.7863849765258216, 'accuracy': 0.8173339399454049, 'roc_auc_score': 0.6463947526853017}",27.715075805783272,"{'f1': 0.4931818181818182, 'precision': 0.7977941176470589, 'accuracy': 0.826070000974944, 'roc_auc_score': 0.6643964393812006}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
55,97.3881443142891,0:00:01,12.165086030960083,0:00:00,"{'f1': 0.4582210242587601, 'precision': 0.7780320366132724, 'accuracy': 0.8171064604185623, 'roc_auc_score': 0.6478867374913836}",27.86018793284893,"{'f1': 0.5022573363431151, 'precision': 0.8003597122302158, 'accuracy': 0.8280198888563908, 'roc_auc_score': 0.6687916701698334}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
56,97.40655662119389,0:00:01,12.167668491601944,0:00:00,"{'f1': 0.4797879390324718, 'precision': 0.7835497835497836, 'accuracy': 0.8214285714285714, 'roc_auc_score': 0.65794505081133}",27.854578912258148,"{'f1': 0.5166297117516631, 'precision': 0.7925170068027211, 'accuracy': 0.8299697767378376, 'roc_auc_score': 0.6760207877921641}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
57,97.60268059372902,0:00:01,12.183078408241272,0:00:00,"{'f1': 0.45466847090663054, 'precision': 0.7795823665893271, 'accuracy': 0.8166515013648772, 'roc_auc_score': 0.6462751144121198}",27.99343892931938,"{'f1': 0.4973125884016973, 'precision': 0.7969174977334542, 'accuracy': 0.8267524617334503, 'roc_auc_score': 0.6664023614847823}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
58,96.69970051944256,0:00:01,12.18989172577858,0:00:00,"{'f1': 0.500973393900065, 'precision': 0.7813765182186235, 'accuracy': 0.8250682438580528, 'roc_auc_score': 0.6682119824789108}",27.87747384607792,"{'f1': 0.533442088091354, 'precision': 0.7873194221508828, 'accuracy': 0.8326996197718631, 'roc_auc_score': 0.684752947914915}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
59,97.10179851949215,0:00:01,12.162377506494522,0:00:00,"{'f1': 0.5045395590142672, 'precision': 0.7858585858585858, 'accuracy': 0.8262056414922657, 'roc_auc_score': 0.6699432438313565}",27.879872918128967,"{'f1': 0.532425068119891, 'precision': 0.7891760904684976, 'accuracy': 0.8326996197718631, 'roc_auc_score': 0.6841861705481757}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
60,96.89524081349373,0:00:01,12.16458809375763,0:00:00,"{'f1': 0.47231487658438953, 'precision': 0.7831858407079646, 'accuracy': 0.8200636942675159, 'roc_auc_score': 0.6544232080568035}",27.845525443553925,"{'f1': 0.5115889416364144, 'precision': 0.7972149695387293, 'accuracy': 0.8294823047674759, 'roc_auc_score': 0.6734341895073147}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
61,97.60448363423347,0:00:01,12.127190798521042,0:00:00,"{'f1': 0.5118665811417576, 'precision': 0.779296875, 'accuracy': 0.8268880800727935, 'roc_auc_score': 0.6736737049335173}",27.990418076515198,"{'f1': 0.5442834138486313, 'precision': 0.7836166924265843, 'accuracy': 0.8344545188651653, 'roc_auc_score': 0.6905790209349253}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
62,97.54366236925125,0:00:01,12.021576419472694,0:00:00,"{'f1': 0.5209656925031766, 'precision': 0.777988614800759, 'accuracy': 0.8284804367606915, 'roc_auc_score': 0.678329615848492}",27.841739892959595,"{'f1': 0.5451137884872824, 'precision': 0.7812739831158864, 'accuracy': 0.834357024471093, 'roc_auc_score': 0.6910819005380864}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
63,97.33745661377907,0:00:01,12.136198937892914,0:00:00,"{'f1': 0.5243209096651926, 'precision': 0.7742537313432836, 'accuracy': 0.8287079162875342, 'roc_auc_score': 0.6801201972505727}",27.748278632760048,"{'f1': 0.5491759702286019, 'precision': 0.7766917293233083, 'accuracy': 0.8346495076533099, 'roc_auc_score': 0.6933990089540946}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
64,97.16190294921398,0:00:01,12.185922235250473,0:00:00,"{'f1': 0.4787798408488064, 'precision': 0.7830802603036876, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6574674958925144}",27.687223106622696,"{'f1': 0.5130919220055711, 'precision': 0.7953367875647669, 'accuracy': 0.8295797991615482, 'roc_auc_score': 0.6742065589793172}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
65,97.32594239711761,0:00:01,12.0625339448452,0:00:00,"{'f1': 0.5115681233933161, 'precision': 0.7819253438113949, 'accuracy': 0.827115559599636, 'roc_auc_score': 0.6734947466107004}",27.73418429493904,"{'f1': 0.5416779066630698, 'precision': 0.7874509803921569, 'accuracy': 0.834357024471093, 'roc_auc_score': 0.689098179754498}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
66,96.9987698495388,0:00:01,12.08563968539238,0:00:00,"{'f1': 0.4716098864395458, 'precision': 0.7844444444444445, 'accuracy': 0.8200636942675159, 'roc_auc_score': 0.6540949514359873}",27.977741733193398,"{'f1': 0.5042205965109735, 'precision': 0.7985739750445633, 'accuracy': 0.8282148776445354, 'roc_auc_score': 0.6697696317470995}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
67,96.96945863962173,0:00:01,12.004259705543518,0:00:00,"{'f1': 0.5006501950585176, 'precision': 0.7841140529531568, 'accuracy': 0.8252957233848953, 'roc_auc_score': 0.6680330241560939}",27.846355199813843,"{'f1': 0.5271530444322545, 'precision': 0.7915980230642504, 'accuracy': 0.8319196646192843, 'roc_auc_score': 0.6814078789725911}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
68,96.97781586647034,0:00:01,12.074733465909958,0:00:00,"{'f1': 0.4756828780812791, 'precision': 0.7863436123348018, 'accuracy': 0.8209736123748863, 'roc_auc_score': 0.6560051711112499}",27.825481444597244,"{'f1': 0.5093653899916131, 'precision': 0.7956331877729258, 'accuracy': 0.8288973384030418, 'roc_auc_score': 0.6723423312174205}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
69,97.16999746859074,0:00:01,12.070371747016907,0:00:00,"{'f1': 0.5172413793103448, 'precision': 0.7803468208092486, 'accuracy': 0.8280254777070064, 'roc_auc_score': 0.6763897361484118}",27.828621983528137,"{'f1': 0.5425731936610261, 'precision': 0.7823392718822618, 'accuracy': 0.8339670468948035, 'roc_auc_score': 0.6896927547502943}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
70,96.59095963835716,0:00:01,12.082073837518692,0:00:00,"{'f1': 0.4695652173913044, 'precision': 0.7834821428571429, 'accuracy': 0.8196087352138307, 'roc_auc_score': 0.6531398415983559}",28.06605088710785,"{'f1': 0.5077138849929874, 'precision': 0.7987643424536628, 'accuracy': 0.8288973384030418, 'roc_auc_score': 0.6714921651673111}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
71,97.11710759997368,0:00:01,12.12914976477623,0:00:00,"{'f1': 0.5086928525434643, 'precision': 0.7806324110671937, 'accuracy': 0.8264331210191083, 'roc_auc_score': 0.6720620818542534}",27.685746625065804,"{'f1': 0.53528773072747, 'precision': 0.7875399361022364, 'accuracy': 0.8330895973481525, 'roc_auc_score': 0.6857170106776526}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
72,96.70723348855972,0:00:01,12.079078882932663,0:00:00,"{'f1': 0.4950884086444008, 'precision': 0.7875, 'accuracy': 0.8246132848043676, 'roc_auc_score': 0.6652873329163819}",27.84959165751934,"{'f1': 0.5247524752475248, 'precision': 0.792358803986711, 'accuracy': 0.831529687042995, 'roc_auc_score': 0.680160427526484}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
73,96.59244087338448,0:00:01,11.994836494326591,0:00:00,"{'f1': 0.5096774193548387, 'precision': 0.7852882703777336, 'accuracy': 0.827115559599636, 'roc_auc_score': 0.6725099767482516}",27.82698553800583,"{'f1': 0.5358306188925082, 'precision': 0.7883386581469649, 'accuracy': 0.8332845861362972, 'roc_auc_score': 0.685986500546494}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
74,96.8322596848011,0:00:01,12.035726487636566,0:00:00,"{'f1': 0.5012953367875647, 'precision': 0.778672032193159, 'accuracy': 0.8248407643312102, 'roc_auc_score': 0.6683909408017276}",27.842362120747566,"{'f1': 0.5330432417731847, 'precision': 0.7871485943775101, 'accuracy': 0.8326021253777908, 'roc_auc_score': 0.6845473558096519}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
75,96.5371572226286,0:00:01,12.130046248435974,0:00:00,"{'f1': 0.48348745046235136, 'precision': 0.7837259100642399, 'accuracy': 0.8221110100090991, 'roc_auc_score': 0.6597059721885932}",27.915164411067963,"{'f1': 0.5166112956810631, 'precision': 0.7906779661016949, 'accuracy': 0.8297747879496928, 'roc_auc_score': 0.6760346866066924}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
76,96.30956304073334,0:00:02,12.093483299016953,0:00:00,"{'f1': 0.49934980494148246, 'precision': 0.7820773930753564, 'accuracy': 0.8248407643312102, 'roc_auc_score': 0.6674061709392788}",27.641595736145973,"{'f1': 0.5265753424657534, 'precision': 0.7889983579638752, 'accuracy': 0.831529687042995, 'roc_auc_score': 0.6811522879182781}",0:00:01,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
77,97.05009889602661,0:00:01,12.083013147115707,0:00:00,"{'f1': 0.4787798408488064, 'precision': 0.7830802603036876, 'accuracy': 0.8212010919017289, 'roc_auc_score': 0.6574674958925144}",27.767701357603073,"{'f1': 0.5133779264214047, 'precision': 0.7967128027681661, 'accuracy': 0.8297747879496928, 'roc_auc_score': 0.6743343545064737}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
78,97.04963584244251,0:00:01,12.183138936758041,0:00:00,"{'f1': 0.5308176100628931, 'precision': 0.7771639042357275, 'accuracy': 0.8303002729754322, 'roc_auc_score': 0.6834630816822824}",27.701171025633812,"{'f1': 0.5520529801324504, 'precision': 0.7758749069247952, 'accuracy': 0.8351369796236716, 'roc_auc_score': 0.6949937468471498}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
79,96.94418379664421,0:00:01,12.11499810218811,0:00:00,"{'f1': 0.48918032786885246, 'precision': 0.7803347280334728, 'accuracy': 0.8227934485896269, 'roc_auc_score': 0.6624516634283053}",27.74089640378952,"{'f1': 0.5214994487320839, 'precision': 0.7909698996655519, 'accuracy': 0.8307497318904163, 'roc_auc_score': 0.6785156906843787}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
80,96.82372803986073,0:00:01,12.068499147891998,0:00:00,"{'f1': 0.4793608521970705, 'precision': 0.7912087912087912, 'accuracy': 0.8221110100090991, 'roc_auc_score': 0.6577364324636956}",27.937890753149986,"{'f1': 0.5107451855986603, 'precision': 0.7949609035621199, 'accuracy': 0.8290923271911865, 'roc_auc_score': 0.6730369041113167}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
81,96.59238567203283,0:00:01,12.113923713564873,0:00:00,"{'f1': 0.4947643979057591, 'precision': 0.7858627858627859, 'accuracy': 0.824385805277525, 'roc_auc_score': 0.6651380346183824}",27.88456954061985,"{'f1': 0.5247524752475248, 'precision': 0.792358803986711, 'accuracy': 0.831529687042995, 'roc_auc_score': 0.680160427526484}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
82,96.47997044026852,0:00:01,12.110490292310715,0:00:00,"{'f1': 0.4937949052906597, 'precision': 0.78099173553719, 'accuracy': 0.8237033666969973, 'roc_auc_score': 0.6646901397243842}",27.594979882240295,"{'f1': 0.5249588590235875, 'precision': 0.7883031301482701, 'accuracy': 0.8311397094667057, 'roc_auc_score': 0.6803299194972255}",0:00:00,20220117_1713,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
83,96.80775819718838,0:00:01,12.098204225301743,0:00:00,"{'f1': 0.510939510939511, 'precision': 0.7830374753451677, 'accuracy': 0.827115559599636, 'roc_auc_score': 0.6731664899898843}",27.627212956547737,"{'f1': 0.5376925155363416, 'precision': 0.7840819542947203, 'accuracy': 0.8331870917422248, 'roc_auc_score': 0.6870561575163949}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
84,96.4241140037775,0:00:01,12.061869472265244,0:00:00,"{'f1': 0.5150159744408945, 'precision': 0.777992277992278, 'accuracy': 0.8273430391264787, 'roc_auc_score': 0.6752853280127812}",27.874571293592453,"{'f1': 0.5406569736133549, 'precision': 0.7831513260530422, 'accuracy': 0.8336745637125865, 'roc_auc_score': 0.6886508954094501}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
85,96.92990897595882,0:00:01,12.16198804974556,0:00:00,"{'f1': 0.5229007633587787, 'precision': 0.7828571428571428, 'accuracy': 0.8293903548680619, 'roc_auc_score': 0.6792550656613059}",27.728652149438858,"{'f1': 0.5433091981764548, 'precision': 0.7810331534309946, 'accuracy': 0.8339670468948035, 'roc_auc_score': 0.690117837775349}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
86,96.41892646253109,0:00:02,12.110482454299927,0:00:00,"{'f1': 0.4861660079051384, 'precision': 0.7834394904458599, 'accuracy': 0.8225659690627843, 'roc_auc_score': 0.6609893386470409}",27.711754113435745,"{'f1': 0.522075055187638, 'precision': 0.7936241610738255, 'accuracy': 0.8311397094667057, 'roc_auc_score': 0.6787712817386918}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
87,96.99032106995583,0:00:01,12.057667911052704,0:00:00,"{'f1': 0.49706457925636, 'precision': 0.7839506172839507, 'accuracy': 0.8246132848043676, 'roc_auc_score': 0.6662721027788305}",27.8811347335577,"{'f1': 0.5297651556526488, 'precision': 0.7886178861788617, 'accuracy': 0.8321146534074291, 'roc_auc_score': 0.6828109235749118}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
88,96.98384940624237,0:00:01,12.05212751030922,0:00:00,"{'f1': 0.5042125729099157, 'precision': 0.7842741935483871, 'accuracy': 0.8259781619654231, 'roc_auc_score': 0.6697939455333571}",27.81969228386879,"{'f1': 0.5358306188925082, 'precision': 0.7883386581469649, 'accuracy': 0.8332845861362972, 'roc_auc_score': 0.685986500546494}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
89,96.81449861824512,0:00:01,12.023876458406448,0:00:00,"{'f1': 0.49411764705882355, 'precision': 0.782608695652174, 'accuracy': 0.8239308462238398, 'roc_auc_score': 0.6648394380223835}",27.7969231903553,"{'f1': 0.5290251916757941, 'precision': 0.7918032786885246, 'accuracy': 0.8323096421955738, 'roc_auc_score': 0.6823719417353287}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
90,96.91376981139183,0:00:01,12.117270112037659,0:00:00,"{'f1': 0.5249841872232764, 'precision': 0.7771535580524345, 'accuracy': 0.8291628753412192, 'roc_auc_score': 0.6804187938465716}",27.681142807006836,"{'f1': 0.5489882854100107, 'precision': 0.7787009063444109, 'accuracy': 0.8348444964414546, 'roc_auc_score': 0.6932434157978813}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
91,96.49197459220886,0:00:01,12.055443942546844,0:00:00,"{'f1': 0.48883048620236536, 'precision': 0.783157894736842, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6622727051054884}",27.738043069839478,"{'f1': 0.5237964236588721, 'precision': 0.7913549459684123, 'accuracy': 0.831237203860778, 'roc_auc_score': 0.6796853455523794}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
92,97.36238870024681,0:00:01,12.031796544790268,0:00:00,"{'f1': 0.5087153001936733, 'precision': 0.7848605577689243, 'accuracy': 0.8268880800727935, 'roc_auc_score': 0.672032421829436}",27.84127101302147,"{'f1': 0.5361494719740049, 'precision': 0.7850911974623315, 'accuracy': 0.8329921029540801, 'roc_auc_score': 0.6862198902808139}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
93,96.89806996285915,0:00:01,12.079341560602188,0:00:00,"{'f1': 0.4901445466491458, 'precision': 0.7852631578947369, 'accuracy': 0.8234758871701547, 'roc_auc_score': 0.6628995583223036}",27.619103208184242,"{'f1': 0.5230090934141637, 'precision': 0.7928153717627402, 'accuracy': 0.831237203860778, 'roc_auc_score': 0.6792602625273247}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
94,96.3207012116909,0:00:01,12.070338100194931,0:00:00,"{'f1': 0.4937949052906597, 'precision': 0.78099173553719, 'accuracy': 0.8237033666969973, 'roc_auc_score': 0.6646901397243842}",27.56581000983715,"{'f1': 0.5259686727122836, 'precision': 0.7928748964374482, 'accuracy': 0.8318221702252121, 'roc_auc_score': 0.6807772038422735}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
95,96.24907550215721,0:00:01,12.149459183216095,0:00:00,"{'f1': 0.48111332007952284, 'precision': 0.7857142857142857, 'accuracy': 0.8218835304822566, 'roc_auc_score': 0.658571904028145}",28.012554436922073,"{'f1': 0.5155728587319244, 'precision': 0.7963917525773195, 'accuracy': 0.8301647655259823, 'roc_auc_score': 0.6754401116108962}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
96,96.85877822339535,0:00:01,12.13942375779152,0:00:00,"{'f1': 0.49376231122783976, 'precision': 0.7899159663865546, 'accuracy': 0.8246132848043676, 'roc_auc_score': 0.6646308196747492}",27.640170991420746,"{'f1': 0.5253025302530252, 'precision': 0.7931893687707641, 'accuracy': 0.8317246758311397, 'roc_auc_score': 0.6804299173953253}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
97,96.11535511910915,0:00:01,12.078004330396652,0:00:00,"{'f1': 0.5058365758754864, 'precision': 0.7878787878787878, 'accuracy': 0.8266606005459509, 'roc_auc_score': 0.6705700970481716}",27.668333262205124,"{'f1': 0.5334784975503538, 'precision': 0.789049919484702, 'accuracy': 0.8328946085600079, 'roc_auc_score': 0.6847390491003866}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
98,96.46508556604385,0:00:01,12.092753112316132,0:00:00,"{'f1': 0.4848084544253633, 'precision': 0.7858672376873662, 'accuracy': 0.8225659690627843, 'roc_auc_score': 0.6603328254054084}",27.523654222488403,"{'f1': 0.5208505937586303, 'precision': 0.7931034482758621, 'accuracy': 0.8308472262844886, 'roc_auc_score': 0.6781545054229022}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
99,96.75690618157387,0:00:01,11.992329597473145,0:00:00,"{'f1': 0.5233881163084703, 'precision': 0.7738317757009345, 'accuracy': 0.8284804367606915, 'roc_auc_score': 0.6796426423317572}",27.734355613589287,"{'f1': 0.5459401709401709, 'precision': 0.7789634146341463, 'accuracy': 0.8342595300770206, 'roc_auc_score': 0.6915847801412477}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss
100,96.56977185606956,0:00:01,12.11660361289978,0:00:00,"{'f1': 0.5071151358344114, 'precision': 0.7855711422845691, 'accuracy': 0.8266606005459509, 'roc_auc_score': 0.6712266102898041}",27.583640441298485,"{'f1': 0.5344546934346175, 'precision': 0.7854864433811802, 'accuracy': 0.8326996197718631, 'roc_auc_score': 0.6853197252816545}",0:00:00,20220117_1714,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_deepcross/results/Model_LR0.0002_Batch128_LossBCEWithLogitsLoss

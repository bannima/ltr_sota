Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,132.59745210409164,0:00:04,14.280827105045319,0:00:00,"{'f1': 0.30381679389312977, 'precision': 0.7566539923954373, 'accuracy': 0.7925386715195633, 'roc_auc_score': 0.5854783377723554}",32.901850163936615,"{'f1': 0.2943495400788436, 'precision': 0.7320261437908496, 'accuracy': 0.7905820415326119, 'roc_auc_score': 0.5816260299310576}",0:00:01,20220119_1548,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
2,111.3315099477768,0:00:04,13.271703124046326,0:00:00,"{'f1': 0.4383934649421375, 'precision': 0.7630331753554502, 'accuracy': 0.8123293903548681, 'roc_auc_score': 0.6388428540587034}",30.705844581127167,"{'f1': 0.45840504876649457, 'precision': 0.7580645161290323, 'accuracy': 0.8159305839914205, 'roc_auc_score': 0.6479741623928031}",0:00:01,20220119_1548,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
3,107.66568607091904,0:00:04,12.934776663780212,0:00:00,"{'f1': 0.4665792922673656, 'precision': 0.7432150313152401, 'accuracy': 0.8148316651501365, 'roc_auc_score': 0.6516458604444498}",30.072268217802048,"{'f1': 0.5021881838074398, 'precision': 0.75, 'accuracy': 0.8225602027883396, 'roc_auc_score': 0.6691808369766269}",0:00:01,20220119_1548,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
4,105.06788039207458,0:00:04,12.951588898897171,0:00:00,"{'f1': 0.4238227146814405, 'precision': 0.7707808564231738, 'accuracy': 0.8107370336669699, 'roc_auc_score': 0.6325456600396475}",29.77382004261017,"{'f1': 0.4463145676146256, 'precision': 0.7583826429980276, 'accuracy': 0.8139806961099737, 'roc_auc_score': 0.642445376870691}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
5,104.239670753479,0:00:04,12.783879488706589,0:00:00,"{'f1': 0.45929847782925215, 'precision': 0.7478448275862069, 'accuracy': 0.8141492265696088, 'roc_auc_score': 0.6482436559631052}",29.517706006765366,"{'f1': 0.47955182072829133, 'precision': 0.7521968365553603, 'accuracy': 0.8188554158135907, 'roc_auc_score': 0.6579676727761897}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
6,102.76346936821938,0:00:04,12.759797602891922,0:00:00,"{'f1': 0.49073482428115006, 'precision': 0.7413127413127413, 'accuracy': 0.8186988171064604, 'roc_auc_score': 0.6633751168932949}",29.365159958600998,"{'f1': 0.5209994683678895, 'precision': 0.7368421052631579, 'accuracy': 0.8243151018816418, 'roc_auc_score': 0.6791160459054985}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
7,102.80975419282913,0:00:04,12.775749534368515,0:00:00,"{'f1': 0.4511784511784512, 'precision': 0.7648401826484018, 'accuracy': 0.814604185623294, 'roc_auc_score': 0.6446031731093088}",29.360401451587677,"{'f1': 0.47934813149761163, 'precision': 0.7568766637089619, 'accuracy': 0.8193428877839525, 'roc_auc_score': 0.6578620785690265}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
8,101.90764084458351,0:00:04,12.666419923305511,0:00:00,"{'f1': 0.47213114754098356, 'precision': 0.7531380753138075, 'accuracy': 0.8168789808917197, 'roc_auc_score': 0.6543025716097095}",29.17782062292099,"{'f1': 0.4999999999999999, 'precision': 0.7516501650165016, 'accuracy': 0.822365214000195, 'roc_auc_score': 0.6680611810576762}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
9,101.64561200141907,0:00:04,12.659169435501099,0:00:00,"{'f1': 0.4761904761904762, 'precision': 0.7510288065843621, 'accuracy': 0.8173339399454049, 'roc_auc_score': 0.6562424513097896}",29.16578882932663,"{'f1': 0.504774897680764, 'precision': 0.7502027575020276, 'accuracy': 0.8230476747587013, 'roc_auc_score': 0.6704921861863125}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
10,101.65257441997528,0:00:04,12.673221081495285,0:00:00,"{'f1': 0.47911227154046987, 'precision': 0.756701030927835, 'accuracy': 0.8184713375796179, 'roc_auc_score': 0.6576454560414191}",29.305738851428032,"{'f1': 0.5027382256297919, 'precision': 0.7524590163934426, 'accuracy': 0.8229501803646291, 'roc_auc_score': 0.66943642803094}",0:00:01,20220119_1549,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss

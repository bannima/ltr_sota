Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,130.3281574845314,0:00:24,13.611684560775757,0:00:01,"{'f1': 0.4388586956521739, 'precision': 0.76, 'accuracy': 0.8121019108280255, 'roc_auc_score': 0.6390218123815203}",30.61880138516426,"{'f1': 0.4638674664381605, 'precision': 0.7595884003741815, 'accuracy': 0.8170030223262162, 'roc_auc_score': 0.6505190642340676}",0:00:04,20220119_1550,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
2,108.20856530964375,0:00:24,13.321613520383835,0:00:01,"{'f1': 0.4222222222222222, 'precision': 0.7735368956743003, 'accuracy': 0.8107370336669699, 'roc_auc_score': 0.6318891467980149}",29.719127595424652,"{'f1': 0.45686160972785184, 'precision': 0.7720156555772995, 'accuracy': 0.8171005167202886, 'roc_auc_score': 0.6473239921388936}",0:00:04,20220119_1551,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
3,105.4759946167469,0:00:24,13.204748630523682,0:00:01,"{'f1': 0.5068664169787764, 'precision': 0.7315315315315315, 'accuracy': 0.8202911737943585, 'roc_auc_score': 0.6716418506372486}",30.00104483962059,"{'f1': 0.540115364446775, 'precision': 0.7452966714905933, 'accuracy': 0.8289948327971142, 'roc_auc_score': 0.6892678556415}",0:00:04,20220119_1551,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
4,103.26919412612915,0:00:24,12.687478512525558,0:00:01,"{'f1': 0.5149625935162094, 'precision': 0.7414721723518851, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6757312265589551}",29.013139575719833,"{'f1': 0.5300053106744557, 'precision': 0.7481259370314842, 'accuracy': 0.8274349224919567, 'roc_auc_score': 0.6837112724903313}",0:00:04,20220119_1551,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
5,102.36795997619629,0:00:24,12.843482285737991,0:00:01,"{'f1': 0.44919786096256686, 'precision': 0.7483296213808464, 'accuracy': 0.8125568698817106, 'roc_auc_score': 0.6435877450481305}",28.85323664546013,"{'f1': 0.47963800904977366, 'precision': 0.7681159420289855, 'accuracy': 0.8206103149068928, 'roc_auc_score': 0.6579842777871195}",0:00:04,20220119_1552,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
6,101.65231183171272,0:00:24,12.757947266101837,0:00:01,"{'f1': 0.4347231715652768, 'precision': 0.7644230769230769, 'accuracy': 0.8118744313011829, 'roc_auc_score': 0.6372312309794396}",29.273999750614166,"{'f1': 0.474373576309795, 'precision': 0.7712962962962963, 'accuracy': 0.8200253485424588, 'roc_auc_score': 0.6554754760803766}",0:00:04,20220119_1552,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
7,101.48570796847343,0:00:24,12.549575865268707,0:00:01,"{'f1': 0.5176908752327747, 'precision': 0.7393617021276596, 'accuracy': 0.8232484076433121, 'roc_auc_score': 0.6771935513402195}",28.490964487195015,"{'f1': 0.5383806519453207, 'precision': 0.7463556851311953, 'accuracy': 0.8287998440089694, 'roc_auc_score': 0.688289894064234}",0:00:04,20220119_1553,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
8,100.85477174818516,0:00:24,12.856813937425613,0:00:01,"{'f1': 0.43043180260452363, 'precision': 0.7621359223300971, 'accuracy': 0.8109645131938126, 'roc_auc_score': 0.635321011304177}",29.357395738363266,"{'f1': 0.4655024334383052, 'precision': 0.7662582469368521, 'accuracy': 0.8179779662669396, 'roc_auc_score': 0.6512997362115353}",0:00:04,20220119_1553,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
9,99.9088781774044,0:00:24,12.720283687114716,0:00:01,"{'f1': 0.47786458333333326, 'precision': 0.7505112474437627, 'accuracy': 0.8175614194722475, 'roc_auc_score': 0.6570482628494215}",28.772487580776215,"{'f1': 0.5075280591294826, 'precision': 0.7592137592137592, 'accuracy': 0.8246075850638588, 'roc_auc_score': 0.6717979390869346}",0:00:04,20220119_1554,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss
10,100.07705256342888,0:00:24,12.699982523918152,0:00:01,"{'f1': 0.4900321543408361, 'precision': 0.75, 'accuracy': 0.8196087352138307, 'roc_auc_score': 0.6629875402228438}",28.498146414756775,"{'f1': 0.5142392188771359, 'precision': 0.7553784860557768, 'accuracy': 0.8253875402164376, 'roc_auc_score': 0.6752847023709433}",0:00:04,20220119_1554,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_fm/results/Model_LR0.0005_Batch128_LossBCEWithLogitsLoss

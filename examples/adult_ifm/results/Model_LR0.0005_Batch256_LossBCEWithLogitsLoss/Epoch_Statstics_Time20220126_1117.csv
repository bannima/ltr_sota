Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,61.0608976483345,0:00:06,6.753385931253433,0:00:00,"{'f1': 0.5125313283208021, 'precision': 0.7449908925318761, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6744182000756902}",15.133974850177765,"{'f1': 0.54375, 'precision': 0.7414772727272727, 'accuracy': 0.8291898215852589, 'roc_auc_score': 0.6913793719522447}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
2,51.68228814005852,0:00:06,6.610257714986801,0:00:00,"{'f1': 0.5566765578635015, 'precision': 0.7351097178683386, 'accuracy': 0.8300727934485896, 'roc_auc_score': 0.6987418445626472}",14.95835691690445,"{'f1': 0.5746955008699974, 'precision': 0.7265870521684475, 'accuracy': 0.8331870917422248, 'roc_auc_score': 0.709868946527661}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
3,50.901381969451904,0:00:06,6.575013160705566,0:00:00,"{'f1': 0.5082174462705435, 'precision': 0.7514018691588785, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6721204037299764}",14.616843909025192,"{'f1': 0.5369340746624305, 'precision': 0.753903345724907, 'accuracy': 0.8294823047674759, 'roc_auc_score': 0.6873202349924332}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
4,50.15691202878952,0:00:06,6.698767125606537,0:00:00,"{'f1': 0.44095563139931737, 'precision': 0.7727272727272727, 'accuracy': 0.8136942675159236, 'roc_auc_score': 0.6400669004675161}",14.521152317523956,"{'f1': 0.47224618924360084, 'precision': 0.785645933014354, 'accuracy': 0.8210977868772545, 'roc_auc_score': 0.6544780193795191}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
5,49.94090020656586,0:00:06,6.4877913892269135,0:00:00,"{'f1': 0.43711340206185567, 'precision': 0.7794117647058824, 'accuracy': 0.8136942675159236, 'roc_auc_score': 0.6384256173634348}",14.555954068899155,"{'f1': 0.47264394156402173, 'precision': 0.7790368271954674, 'accuracy': 0.8205128205128205, 'roc_auc_score': 0.6546614101647891}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
6,49.45895892381668,0:00:06,6.449679493904114,0:00:00,"{'f1': 0.5307881773399015, 'precision': 0.7469670710571924, 'accuracy': 0.8266606005459509, 'roc_auc_score': 0.6840286185016383}",14.525170892477036,"{'f1': 0.5557851239669422, 'precision': 0.7472222222222222, 'accuracy': 0.8323096421955738, 'roc_auc_score': 0.6979583193206658}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
7,49.132067531347275,0:00:06,6.439775317907333,0:00:00,"{'f1': 0.42777777777777776, 'precision': 0.7837150127226463, 'accuracy': 0.8125568698817106, 'roc_auc_score': 0.6343965596652752}",14.321546018123627,"{'f1': 0.46122448979591835, 'precision': 0.7925851703406813, 'accuracy': 0.8198303597543142, 'roc_auc_score': 0.649396518202455}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
8,49.08391371369362,0:00:06,6.560040175914764,0:00:00,"{'f1': 0.5373493975903615, 'precision': 0.7275693311582382, 'accuracy': 0.8252957233848953, 'roc_auc_score': 0.6880566780258857}",14.235732406377792,"{'f1': 0.571790969051243, 'precision': 0.7463576158940397, 'accuracy': 0.8354294628058887, 'roc_auc_score': 0.7072294591810998}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
9,48.518810868263245,0:00:06,6.449822574853897,0:00:00,"{'f1': 0.5288640595903166, 'precision': 0.7553191489361702, 'accuracy': 0.8273430391264787, 'roc_auc_score': 0.6828352302915552}",14.678068697452545,"{'f1': 0.5558455114822547, 'precision': 0.7607142857142857, 'accuracy': 0.8340645412888759, 'roc_auc_score': 0.6975498413065412}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
10,48.61195468902588,0:00:06,6.496374189853668,0:00:00,"{'f1': 0.5022595222724339, 'precision': 0.7749003984063745, 'accuracy': 0.8246132848043676, 'roc_auc_score': 0.6688981557453607}",14.22482430934906,"{'f1': 0.5269137138220178, 'precision': 0.7699604743083004, 'accuracy': 0.8294823047674759, 'roc_auc_score': 0.6816524613250379}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
11,48.384901374578476,0:00:06,6.305316045880318,0:00:00,"{'f1': 0.5266418835192069, 'precision': 0.7495590828924162, 'accuracy': 0.8262056414922657, 'roc_auc_score': 0.6817604821807418}",14.253228664398193,"{'f1': 0.5580670303975058, 'precision': 0.757939308398024, 'accuracy': 0.8341620356829482, 'roc_auc_score': 0.6988889881452833}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss
12,48.08481439948082,0:00:06,6.295063927769661,0:00:00,"{'f1': 0.5209244222361025, 'precision': 0.7527075812274369, 'accuracy': 0.825523202911738, 'roc_auc_score': 0.6786865343202135}",14.289524644613266,"{'f1': 0.5508385744234802, 'precision': 0.759393063583815, 'accuracy': 0.8328946085600079, 'roc_auc_score': 0.6947993473600135}",0:00:01,20220126_1117,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.0005_Batch256_LossBCEWithLogitsLoss

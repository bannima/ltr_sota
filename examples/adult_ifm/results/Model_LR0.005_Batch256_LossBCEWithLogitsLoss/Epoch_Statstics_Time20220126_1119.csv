Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,80.04844546318054,0:00:06,7.365642756223679,0:00:00,"{'f1': 0.4690553745928339, 'precision': 0.7377049180327869, 'accuracy': 0.814604185623294, 'roc_auc_score': 0.6528095886297154}",16.502452045679092,"{'f1': 0.4990568579897601, 'precision': 0.7240031274433151, 'accuracy': 0.8187579214195184, 'roc_auc_score': 0.6678223789305532}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
2,60.67462468147278,0:00:06,7.481790632009506,0:00:00,"{'f1': 0.5252894576477758, 'precision': 0.7255892255892256, 'accuracy': 0.8227934485896269, 'roc_auc_score': 0.6814905474356484}",15.998997420072556,"{'f1': 0.539820742637644, 'precision': 0.7155465037338764, 'accuracy': 0.8248025738520035, 'roc_auc_score': 0.6899209160080713}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
3,57.02372434735298,0:00:06,6.660282492637634,0:00:00,"{'f1': 0.5153751537515375, 'precision': 0.7236614853195165, 'accuracy': 0.8207461328480437, 'roc_auc_score': 0.6762077833038587}",15.092695504426956,"{'f1': 0.5206415987378386, 'precision': 0.7221006564551422, 'accuracy': 0.8222677196061227, 'roc_auc_score': 0.6791911362872036}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
4,52.66290035843849,0:00:06,6.544821560382843,0:00:00,"{'f1': 0.5338983050847457, 'precision': 0.7289256198347107, 'accuracy': 0.8248407643312102, 'roc_auc_score': 0.6861167983258057}",14.546109527349472,"{'f1': 0.5451254202223945, 'precision': 0.7344947735191638, 'accuracy': 0.8285073608267525, 'roc_auc_score': 0.6923490310240457}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
5,50.56389316916466,0:00:06,6.376623779535294,0:00:00,"{'f1': 0.5127566894835096, 'precision': 0.7357142857142858, 'accuracy': 0.8218835304822566, 'roc_auc_score': 0.6746564784481418}",14.441313564777374,"{'f1': 0.5420267085624509, 'precision': 0.7462148521989906, 'accuracy': 0.8294823047674759, 'roc_auc_score': 0.6902958161678157}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
6,49.52193543314934,0:00:06,6.31250536441803,0:00:00,"{'f1': 0.5351252290775809, 'precision': 0.7423728813559322, 'accuracy': 0.8268880800727935, 'roc_auc_score': 0.6864757131453515}",14.183796867728233,"{'f1': 0.5526179367547953, 'precision': 0.7475455820476858, 'accuracy': 0.8317246758311397, 'roc_auc_score': 0.6961579893223473}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
7,48.956064224243164,0:00:06,6.444825321435928,0:00:00,"{'f1': 0.5312693498452012, 'precision': 0.7552816901408451, 'accuracy': 0.8277979981801638, 'roc_auc_score': 0.6841185967500029}",14.207464277744293,"{'f1': 0.5502070393374742, 'precision': 0.74231843575419, 'accuracy': 0.8305547431022716, 'roc_auc_score': 0.6949661331343534}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
8,48.38457506895065,0:00:06,6.2543177008628845,0:00:00,"{'f1': 0.5081967213114754, 'precision': 0.7476808905380334, 'accuracy': 0.8225659690627843, 'roc_auc_score': 0.6721500637547938}",14.25236400961876,"{'f1': 0.5336870026525198, 'precision': 0.7518684603886397, 'accuracy': 0.8286048552208248, 'roc_auc_score': 0.6856116003867496}",0:00:01,20220126_1118,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
9,48.27103805541992,0:00:06,6.391440033912659,0:00:00,"{'f1': 0.5327669902912622, 'precision': 0.7304492512479202, 'accuracy': 0.8248407643312102, 'roc_auc_score': 0.6854602850841731}",14.28353801369667,"{'f1': 0.5590189064895248, 'precision': 0.738191632928475, 'accuracy': 0.8317246758311397, 'roc_auc_score': 0.7001254308895241}",0:00:01,20220126_1119,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
10,47.88576382398605,0:00:06,6.3009220361709595,0:00:00,"{'f1': 0.5308641975308641, 'precision': 0.7504363001745201, 'accuracy': 0.827115559599636, 'roc_auc_score': 0.6839989584768209}",14.069816663861275,"{'f1': 0.5566208862399585, 'precision': 0.7526278906797477, 'accuracy': 0.8331870917422248, 'roc_auc_score': 0.6982500105095006}",0:00:01,20220126_1119,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
11,47.55545289814472,0:00:06,6.2163082510232925,0:00:00,"{'f1': 0.5184721352536006, 'precision': 0.7527272727272727, 'accuracy': 0.8250682438580528, 'roc_auc_score': 0.6774031678617661}",14.001876577734947,"{'f1': 0.550603041426324, 'precision': 0.7597684515195369, 'accuracy': 0.8328946085600079, 'roc_auc_score': 0.6946576530183286}",0:00:01,20220126_1119,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
12,47.57722660899162,0:00:06,6.2832179963588715,0:00:00,"{'f1': 0.5166561910747958, 'precision': 0.7555147058823529, 'accuracy': 0.8250682438580528, 'roc_auc_score': 0.6764183979993172}",14.281751811504364,"{'f1': 0.5413811280969953, 'precision': 0.7540381791483113, 'accuracy': 0.8303597543141269, 'roc_auc_score': 0.6897373413065411}",0:00:01,20220126_1119,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss

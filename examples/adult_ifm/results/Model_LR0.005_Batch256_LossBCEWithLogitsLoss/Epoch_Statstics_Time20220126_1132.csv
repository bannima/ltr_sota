Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,65.3756433725357,0:00:06,7.132475674152374,0:00:00,"{'f1': 0.5542439572793705, 'precision': 0.6734972677595629, 'accuracy': 0.8196087352138307, 'roc_auc_score': 0.6997522817542648}",15.77003699541092,"{'f1': 0.577121425222691, 'precision': 0.6712104689203926, 'accuracy': 0.8241201130934971, 'roc_auc_score': 0.7145535301412477}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
2,57.89884656667709,0:00:06,6.930557608604431,0:00:00,"{'f1': 0.5509391007398975, 'precision': 0.6816901408450704, 'accuracy': 0.8205186533212011, 'roc_auc_score': 0.6973951653589163}",15.263456374406815,"{'f1': 0.5688695231178892, 'precision': 0.6915832842848735, 'accuracy': 0.826362484157161, 'roc_auc_score': 0.7080882955691945}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
3,55.428962886333466,0:00:06,6.826989948749542,0:00:00,"{'f1': 0.5584112149532711, 'precision': 0.718796992481203, 'accuracy': 0.8280254777070064, 'roc_auc_score': 0.700352469467999}",15.421947807073593,"{'f1': 0.5708582834331337, 'precision': 0.7258883248730964, 'accuracy': 0.8323096421955738, 'roc_auc_score': 0.7075935345552379}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
4,52.99530577659607,0:00:06,6.48528665304184,0:00:00,"{'f1': 0.4809960681520315, 'precision': 0.7661795407098121, 'accuracy': 0.8198362147406734, 'roc_auc_score': 0.6585412458294154}",14.646743714809418,"{'f1': 0.487710577188622, 'precision': 0.7426408746846089, 'accuracy': 0.8191478989958078, 'roc_auc_score': 0.6619851132924163}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
5,50.854411751031876,0:00:06,6.444280058145523,0:00:00,"{'f1': 0.5607911576497964, 'precision': 0.7172619047619048, 'accuracy': 0.828252957233849, 'roc_auc_score': 0.7018147942492634}",14.662886917591095,"{'f1': 0.5876288659793816, 'precision': 0.7289890377588307, 'accuracy': 0.8362094179584674, 'roc_auc_score': 0.7176592452076677}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
6,50.34867638349533,0:00:06,6.429989904165268,0:00:00,"{'f1': 0.39857142857142863, 'precision': 0.7903682719546742, 'accuracy': 0.8084622383985441, 'roc_auc_score': 0.6221897482976144}",14.69640964269638,"{'f1': 0.42366298177472367, 'precision': 0.774863387978142, 'accuracy': 0.8119333138344546, 'roc_auc_score': 0.6326018633344543}",0:00:01,20220126_1131,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
7,49.601860880851746,0:00:06,6.345684677362442,0:00:00,"{'f1': 0.5385556915544676, 'precision': 0.7495741056218058, 'accuracy': 0.8284804367606915, 'roc_auc_score': 0.6881773144729799}",14.557703346014023,"{'f1': 0.549467670734874, 'precision': 0.7455954897815363, 'accuracy': 0.8308472262844886, 'roc_auc_score': 0.6944493547166637}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
8,48.99098363518715,0:00:06,6.453902751207352,0:00:00,"{'f1': 0.5161691542288558, 'precision': 0.7397504456327986, 'accuracy': 0.8230209281164695, 'roc_auc_score': 0.6763877398005878}",14.168661296367645,"{'f1': 0.5365597054182009, 'precision': 0.7445255474452555, 'accuracy': 0.8282148776445354, 'roc_auc_score': 0.6873397301160249}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
9,48.555742651224136,0:00:06,6.372578948736191,0:00:00,"{'f1': 0.5594322885866351, 'precision': 0.734472049689441, 'accuracy': 0.8305277525022748, 'roc_auc_score': 0.7003534676419111}",14.315830022096634,"{'f1': 0.5790790790790791, 'precision': 0.739769820971867, 'accuracy': 0.8360144291703228, 'roc_auc_score': 0.7118636760131158}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
10,48.05318087339401,0:00:06,6.342973679304123,0:00:00,"{'f1': 0.5160883280757097, 'precision': 0.7602230483271375, 'accuracy': 0.825523202911738, 'roc_auc_score': 0.6760604813536836}",13.983577653765678,"{'f1': 0.5370124701512338, 'precision': 0.7569184741959611, 'accuracy': 0.8298722823437652, 'roc_auc_score': 0.6872924373633765}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
11,47.81183123588562,0:00:06,6.259474992752075,0:00:00,"{'f1': 0.5035233824471493, 'precision': 0.7645914396887159, 'accuracy': 0.8237033666969973, 'roc_auc_score': 0.6696139890366282}",14.179783880710602,"{'f1': 0.5221382289416846, 'precision': 0.7602201257861635, 'accuracy': 0.8274349224919567, 'roc_auc_score': 0.6793187478980999}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss
12,47.516635954380035,0:00:06,6.2346563041210175,0:00:00,"{'f1': 0.5164141414141413, 'precision': 0.7616387337057728, 'accuracy': 0.8257506824385805, 'roc_auc_score': 0.6762097796516829}",14.240408092737198,"{'f1': 0.538788522848034, 'precision': 0.7612612612612613, 'accuracy': 0.8307497318904163, 'roc_auc_score': 0.6881509059189508}",0:00:01,20220126_1132,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR0.005_Batch256_LossBCEWithLogitsLoss

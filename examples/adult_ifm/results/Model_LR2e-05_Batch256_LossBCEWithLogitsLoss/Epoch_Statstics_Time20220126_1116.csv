Epoch,Train Loss,Trian Time,Valid Loss,Valid Time,Eval Metrics,Test Loss,Test Metrics,Test Time,Time,Test Result Dir
1,164.17274701595306,0:00:06,18.779219269752502,0:00:00,"{'f1': 0.3064687168610817, 'precision': 0.21211009174311926, 'accuracy': 0.4049135577797998, 'roc_auc_score': 0.45548329727073583}",42.48820149898529,"{'f1': 0.30137614678899083, 'precision': 0.20896946564885496, 'accuracy': 0.4060641513112996, 'roc_auc_score': 0.45232055027745083}",0:00:01,20220126_1114,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
2,126.69118708372116,0:00:06,13.818002998828888,0:00:00,"{'f1': 0.24967602591792656, 'precision': 0.2279179810725552, 'accuracy': 0.6048680618744313, 'roc_auc_score': 0.4918503377963115}",31.35920488834381,"{'f1': 0.26236162361623616, 'precision': 0.23795180722891565, 'accuracy': 0.6102174124987814, 'roc_auc_score': 0.5006807791743737}",0:00:01,20220126_1114,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
3,93.60078424215317,0:00:06,10.204796075820923,0:00:00,"{'f1': 0.39644218551461247, 'precision': 0.5920303605313093, 'accuracy': 0.783894449499545, 'roc_auc_score': 0.6168980006006155}",23.07773244380951,"{'f1': 0.4288770053475936, 'precision': 0.6131498470948012, 'accuracy': 0.7917519742614799, 'roc_auc_score': 0.6325526000504456}",0:00:01,20220126_1114,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
4,72.4152500629425,0:00:06,8.393681854009628,0:00:00,"{'f1': 0.4056140350877193, 'precision': 0.7645502645502645, 'accuracy': 0.8073248407643312, 'roc_auc_score': 0.62472582301578}",18.980897843837738,"{'f1': 0.4508268059181897, 'precision': 0.7655172413793103, 'accuracy': 0.8154431120210588, 'roc_auc_score': 0.6445373980578443}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
5,63.116089165210724,0:00:06,7.682916671037674,0:00:00,"{'f1': 0.41321152494729446, 'precision': 0.7819148936170213, 'accuracy': 0.8100545950864422, 'roc_auc_score': 0.6281586856958541}",17.114767253398895,"{'f1': 0.458465991316932, 'precision': 0.7741935483870968, 'accuracy': 0.8175879886906503, 'roc_auc_score': 0.6480685639818395}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
6,58.82314547896385,0:00:06,7.472229391336441,0:00:00,"{'f1': 0.42105263157894735, 'precision': 0.7657430730478589, 'accuracy': 0.8098271155595996, 'roc_auc_score': 0.6312919536060174}",16.49801328778267,"{'f1': 0.4641010913268237, 'precision': 0.7695238095238095, 'accuracy': 0.818075460661012, 'roc_auc_score': 0.6506551622666892}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
7,56.67772448062897,0:00:06,7.286831349134445,0:00:00,"{'f1': 0.44952893674293404, 'precision': 0.7608200455580866, 'accuracy': 0.8139217470427661, 'roc_auc_score': 0.6438270215944945}",16.2298042178154,"{'f1': 0.4882022471910112, 'precision': 0.7703900709219859, 'accuracy': 0.822365214000195, 'roc_auc_score': 0.662110018706911}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
8,56.217780381441116,0:00:06,7.179150462150574,0:00:00,"{'f1': 0.44519621109607577, 'precision': 0.7633410672853829, 'accuracy': 0.813466787989081, 'roc_auc_score': 0.6418871418944143}",15.80922383069992,"{'f1': 0.4846435615666385, 'precision': 0.7699194270367055, 'accuracy': 0.8216827532416886, 'roc_auc_score': 0.6603874852866992}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
9,55.10582610964775,0:00:06,7.066507250070572,0:00:00,"{'f1': 0.45399597044996637, 'precision': 0.7647058823529411, 'accuracy': 0.815059144676979, 'roc_auc_score': 0.6458865395677565}",15.886645764112473,"{'f1': 0.49075630252100844, 'precision': 0.7697715289982425, 'accuracy': 0.8227551915764844, 'roc_auc_score': 0.6633574701530183}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
10,54.79883036017418,0:00:06,7.02787372469902,0:00:00,"{'f1': 0.45087483176312243, 'precision': 0.7630979498861048, 'accuracy': 0.8143767060964513, 'roc_auc_score': 0.6444538748113094}",15.778681248426437,"{'f1': 0.4859392575928009, 'precision': 0.7686832740213523, 'accuracy': 0.821780247635761, 'roc_auc_score': 0.6610181604170169}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
11,54.63995781540871,0:00:06,7.112226665019989,0:00:00,"{'f1': 0.45265278710543994, 'precision': 0.7624434389140271, 'accuracy': 0.814604185623294, 'roc_auc_score': 0.6452596863509414}",15.602392345666885,"{'f1': 0.48707865168539327, 'precision': 0.7686170212765957, 'accuracy': 0.8219752364239056, 'roc_auc_score': 0.6615710389692282}",0:00:01,20220126_1115,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
12,54.46804293990135,0:00:06,7.157467603683472,0:00:00,"{'f1': 0.4502688172043011, 'precision': 0.7596371882086168, 'accuracy': 0.8139217470427661, 'roc_auc_score': 0.6441552782153106}",15.833570092916489,"{'f1': 0.48677546426561613, 'precision': 0.7709447415329769, 'accuracy': 0.8221702252120503, 'roc_auc_score': 0.661415445813015}",0:00:01,20220126_1116,/Users/barryzhou/Desktop/Barry2022/codes/ltr/ltr_sota/examples/adult_ifm/results/Model_LR2e-05_Batch256_LossBCEWithLogitsLoss
